import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
import google.generativeai as genai
import re
st.set_page_config(page_title="ì¶©í˜¸ë³¸ë¶€ AI Assistant", layout="wide") 

def get_working_gemini_model():
    genai.configure(api_key=st.secrets["gemini_api_key"])

    # 1) ìš°ì„  í”íˆ ì“°ëŠ” í›„ë³´ë“¤ë¶€í„° ì‹œë„
    candidates = [
        "models/gemini-2.0-flash-lite",
        "models/gemini-2.0-flash-lite-001",
        "models/gemini-2.0-flash",
        "models/gemini-2.0-flash-001",
        "models/gemini-2.5-flash",
        "models/gemini-2.5-pro",
    ]

    for name in candidates:
        try:
            m = genai.GenerativeModel(name)
            # ì•„ì£¼ ì§§ê²Œ í˜¸ì¶œí•´ ëª¨ë¸ ìœ íš¨ì„± í™•ì¸
            _ = m.generate_content("ping")
            return m
        except Exception:
            pass

    # 2) ê·¸ë˜ë„ ì•ˆ ë˜ë©´ list_modelsë¡œ generateContent ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ ì„ íƒ
    try:
        models = list(genai.list_models())
        # ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ëª©ë¡ ì¼ë¶€ í‘œì‹œ(ë””ë²„ê¹…)
        st.sidebar.caption("âœ… Available models:")
        for mm in models[:15]:
            st.sidebar.caption(f"- {mm.name} / {getattr(mm, 'supported_generation_methods', [])}")

        for mm in models:
            methods = getattr(mm, "supported_generation_methods", [])
            if "generateContent" in methods:
                return genai.GenerativeModel(mm.name)  # mm.nameì€ ë³´í†µ "models/..." í˜•íƒœ
    except Exception as e:
        st.sidebar.error(f"list_models ì‹¤íŒ¨: {e}")

    raise RuntimeError("generateContent ì§€ì› ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# --- 1. ì„¤ì • ë° ê¶Œí•œ ---
GOOGLE_SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

@st.cache_resource
def get_gs_client():
    # Streamlit Cloudì˜ Secrets ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    creds = Credentials.from_service_account_info(
        st.secrets["gcp_service_account"], 
        scopes=GOOGLE_SCOPES
    )
    return gspread.authorize(creds)

def fetch_data(sheet_name):
    # 1. URLì´ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ ë‹¤ì‹œ í•œë²ˆ í•˜ë“œì½”ë”© í™•ì¸
    target_url = "https://docs.google.com/spreadsheets/d/1C2tEZ1tGgbhfLw5LsUWrzttByD-zt_CZobg-FVTKyWo/edit"
    
    try:
        if not target_url:
            st.error("êµ¬ê¸€ ì‹œíŠ¸ URL ì£¼ì†Œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return []
            
        client = get_gs_client()
        sh = client.open_by_url(target_url)
        
        # 2. íƒ­ ì´ë¦„ì„ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬ (ì‹œíŠ¸ì— 'ì‚¬ì›ëª…ë¶€'ê°€ ìˆëŠ”ì§€ í™•ì¸)
        worksheet_list = [w.title for w in sh.worksheets()]
        if sheet_name not in worksheet_list:
            st.error(f"'{sheet_name}' íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ íƒ­ ëª©ë¡: {worksheet_list}")
            return []
            
        return sh.worksheet(sheet_name).get_all_records()
    except Exception as e:
        st.error(f"ì—°ë™ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

@st.cache_data(ttl=120)
def fetch_data_cached(sheet_name):
    return fetch_data(sheet_name)


# --- 2. ë¡œê·¸ì¸ í™”ë©´ ---
def login():
    st.title("ğŸ›¡ï¸ ì¶©í˜¸ë³¸ë¶€ ìŠ¤ë§ˆíŠ¸ AI ë¹„ì„œ")
    st.write("ì‚¬ë²ˆìœ¼ë¡œ ë¡œê·¸ì¸í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

    emp_id = st.text_input("ì‚¬ë²ˆ(ID) ì…ë ¥", placeholder="ì‚¬ë²ˆì„ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    if st.button("ë¡œê·¸ì¸", use_container_width=True):
        member_list = fetch_data_cached("ì‚¬ì›ëª…ë¶€")
        # ì‚¬ë²ˆ ë§¤ì¹­ (ì‚¬ë²ˆì´ ìˆ«ìë¡œ ì¸ì‹ë  ìˆ˜ ìˆì–´ strë¡œ ë³€í™˜ ëŒ€ì¡°)
        user = next((row for row in member_list if str(row.get('ì‚¬ë²ˆ')) == emp_id), None)
        
        if user:
            st.session_state["logged_in"] = True
            st.session_state["user_name"] = user.get("ì´ë¦„", "ì‚¬ìš©ì")
            st.rerun()
        else:
            st.error("ì¼ì¹˜í•˜ëŠ” ì‚¬ë²ˆì´ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ì˜ ì‚¬ë²ˆì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

#Top-k ë½‘ëŠ” í•¨ìˆ˜ 2ê°œ ì¶”ê°€
def normalize_tokens(text: str) -> set:
    text = re.sub(r"\s+", " ", str(text)).strip().lower()
    tokens = re.findall(r"[0-9a-zA-Zê°€-í£]+", text)
    return set(tokens)

def pick_top_k_qa(user_query: str, qa_data: list, k: int = 5):
    q_tokens = normalize_tokens(user_query)
    scored = []
    uq_norm = str(user_query).strip().lower()

    for idx, item in enumerate(qa_data):
        q = str(item.get("ì§ˆë¬¸", "")).strip()
        a = str(item.get("ë‹µë³€", "")).strip()
        if not q or not a:
            continue

        q_norm = q.lower()

        # ê¸°ë³¸ í† í° êµì§‘í•© ì ìˆ˜
        score = len(q_tokens & normalize_tokens(q))

        # í•œ ë‹¨ì–´/ì§§ì€ ì§ˆì˜ ë³´ë„ˆìŠ¤
        if uq_norm and uq_norm in q_norm:
            score += 3
        elif q_norm and q_norm in uq_norm:
            score += 2

        scored.append((score, idx, q, a))

    scored.sort(reverse=True, key=lambda x: x[0])
    return scored[:k]


# --- 3. AI ë‹µë³€ ìƒì„± ---
def get_ai_response(user_query):
    user_name = st.session_state.get("user_name", "ì‚¬ìš©ì")

    # 1) ì‹œíŠ¸ ë°ì´í„° ì¡°íšŒ
    qa_data = fetch_data_cached("ì§ˆì˜ì‘ë‹µì‹œíŠ¸")

    if not qa_data:
        return f"{user_name}ë‹˜, í˜„ì¬ ë“±ë¡ëœ ì§€ì¹¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # 2) Top-k ê²€ìƒ‰
    top = pick_top_k_qa(user_query, qa_data, k=5)

    LOW = 1
    HIGH = 5
    top_score = top[0][0] if top else 0

    # 3) LOW: ì°¨ë‹¨ (LLM í˜¸ì¶œ X)
    if top_score < LOW:
        return f"{user_name}ë‹˜, í˜„ì¬ ë“±ë¡ë˜ì§€ ì•Šì€ ì§€ì¹¨ì…ë‹ˆë‹¤. ì§€ì  ë§¤ë‹ˆì €ì—ê²Œ í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤."

    # 4) HIGH: ì§ë°˜í™˜ (LLM í˜¸ì¶œ X)
    if top_score >= HIGH:
        best_score, best_idx, best_q, best_a = top[0]
        return (
            f"{user_name}ë‹˜, ì•„ë˜ ì§€ì¹¨ì„ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.\n\n"
            f"â€¢ {best_a}\n\n"
            f"(ê·¼ê±°: ì§ˆì˜ì‘ë‹µì‹œíŠ¸ #{best_idx+2})"
        )

    # 5) MID: LLM í˜¸ì¶œìš© context êµ¬ì„±
    context_list = []
    for score, idx, q, a in top:
        context_list.append(
            f"[ê·¼ê±°#{idx+2} / score={score}]\n"
            f"Q: {q}\n"
            f"A: {a}"
        )
    context = "\n\n".join(context_list)

    # 6) í”„ë¡¬í”„íŠ¸ ì‘ì„±
    prompt = f"""
ë‹¹ì‹ ì€ KBì†í•´ë³´í—˜ ì¶©ì²­í˜¸ë‚¨ë³¸ë¶€ì˜ 'ì¶©í˜¸ Assistant'ì…ë‹ˆë‹¤.
{user_name}ë‹˜ì—ê²Œ ì¹œì ˆí•˜ê³  ë“ ë“ í•œ íŒŒíŠ¸ë„ˆê°€ ë˜ì–´ì£¼ì„¸ìš”.

[ë‹µë³€ ì›ì¹™]
0. ë‹µë³€ì˜ ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ "{user_name}ë‹˜," ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”.
1. ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ì€ ì•„ë˜ [ì§€ì¹¨ ë°ì´í„°]ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
2. ë°ì´í„°ì— ì—†ëŠ” ê²½ìš° "{user_name}ë‹˜, í˜„ì¬ ë“±ë¡ë˜ì§€ ì•Šì€ ì§€ì¹¨ì…ë‹ˆë‹¤. ì§€ì  ë§¤ë‹ˆì €ì—ê²Œ í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤."ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.
3. ë‹µë³€ì€ ëª¨ë°”ì¼ì—ì„œ ì½ê¸° ì‰½ê²Œ ë¶ˆë ›(â€¢)ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.

[ì§€ì¹¨ ë°ì´í„°]
{context}

ì§ˆë¬¸: {user_query}
"""

    try:
        genai.configure(api_key=st.secrets["gemini_api_key"])
        model = get_working_gemini_model()
        response = model.generate_content(prompt)

        if response and response.text:
            return response.text
        return "AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    except Exception as e:
        msg = str(e)
        if "429" in msg or "Quota exceeded" in msg:
            return (
                f"{user_name}ë‹˜, í˜„ì¬ AI ì²˜ë¦¬ëŸ‰ì´ ë§ì•„ ì ì‹œ ìë™ì‘ë‹µì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                "â€¢ ì§€ê¸ˆì€ ë“±ë¡ëœ ì§€ì¹¨ ê¸°ë°˜ìœ¼ë¡œë§Œ ì•ˆë‚´ë©ë‹ˆë‹¤.\n"
                "â€¢ ì§€ì¹¨ì— ì—†ëŠ” ê²½ìš°: ì§€ì  ë§¤ë‹ˆì € í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
            )
        return f"âš ï¸ ì„œë¹„ìŠ¤ ì¼ì‹œ ì˜¤ë¥˜ (ê´€ë¦¬ì ë¬¸ì˜): {msg}"


#ë©”ì¸ì±„íŒ…í™”ë©´
def main_page():
    
    # --- [ì¶”ê°€ ì‹œì‘] ëª¨ë°”ì¼ ìµœì í™” CSS ë””ìì¸ ---
    st.markdown("""
        <style>
        .stApp { background-color: #F8F9FA; }
        .main-header {
            background: linear-gradient(90deg, #072e6e 0%, #0047AB 100%);
            padding: 25px 20px;
            border-radius: 0 0 20px 20px;
            color: white;
            text-align: center;
            margin: -60px -20px 20px -20px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        div.stButton > button {
            width: 100%; height: 80px; border-radius: 15px;
            background-color: white; border: 1px solid #E0E0E0;
            font-weight: bold; font-size: 16px;
        }
        </style>
    """, unsafe_allow_html=True)

    st.markdown(f"""
        <div class="main-header">
            <h2 style='margin:0;'>ğŸ›ï¸ ì¶©ì²­í˜¸ë‚¨ë³¸ë¶€ AI</h2>
            <p style='margin:5px 0 0 0; opacity:0.8;'>{st.session_state['user_name']}ë‹˜, ì˜¤ëŠ˜ë„ í™”ì´íŒ…!</p>
        </div>
    """, unsafe_allow_html=True)
    # --- [ì¶”ê°€ ë] ---
    
    if st.sidebar.button("ë¡œê·¸ì•„ì›ƒ"):
        del st.session_state["logged_in"]
        st.rerun()
    
  # --- [ì¶”ê°€ ì‹œì‘] í€µ ë©”ë‰´ ë²„íŠ¼ ì˜ì—­ ---
    if "auto_question" not in st.session_state:
        st.session_state.auto_question = None

    st.write("âš¡ **ë¹ ë¥¸ ì—…ë¬´ ì¡°íšŒ**")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“„\nêµ¬ë¹„ì„œë¥˜"):
            st.session_state.auto_question = "ë³´í—˜ê¸ˆ ì²­êµ¬ ì‹œ ê³µí†µ êµ¬ë¹„ì„œë¥˜ ì•Œë ¤ì¤˜"
        if st.button("ğŸ”„\nê³„ì•½ë³€ê²½"):
            st.session_state.auto_question = "ê³„ì•½ì ë³€ê²½ ì‹œ í•„ìš” ì„œë¥˜ ì•Œë ¤ì¤˜"
    with col2:
        if st.button("ğŸ’³\nì¹´ë“œë‚©ë¶€"):
            st.session_state.auto_question = "ë³´í—˜ì‚¬ë³„ ì¹´ë“œë‚©ë¶€ ê°€ëŠ¥ ì—¬ë¶€ ì•Œë ¤ì¤˜"
        if st.button("ğŸ“¢\në³¸ë¶€ì§€ì¹¨"):
            st.session_state.auto_question = "ìµœê·¼ ë³¸ë¶€ ì—…ë¬´ ê³µì§€ì‚¬í•­ ìš”ì•½í•´ì¤˜"
    
    st.divider()
    # --- [ì¶”ê°€ ë] ---

    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # í•˜ë‹¨ ì±„íŒ… ì…ë ¥ì°½
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ìœ„ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”...")
    
    # ë²„íŠ¼ í´ë¦­(auto_question)ì´ ìˆê±°ë‚˜, ì§ì ‘ ì…ë ¥(user_input)ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
    prompt = None
    if st.session_state.auto_question:
        prompt = st.session_state.auto_question
        st.session_state.auto_question = None # ì‚¬ìš© í›„ ë¦¬ì…‹
    elif user_input:
        prompt = user_input

    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ì—¬ê¸°ì„œ ê¸°ì¡´ ì½”ë“œì˜ ë‹µë³€ ìƒì„± ë¡œì§(get_working_gemini_model ë“±)ì„ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.
        # (ê¸°ì¡´ handle_question í•¨ìˆ˜ê°€ ìˆë‹¤ë©´ í˜¸ì¶œ, ì—†ë‹¤ë©´ ì•„ë˜ì— êµ¬í˜„)

        with st.chat_message("assistant"):
            with st.spinner("ì§€ì¹¨ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                answer = get_ai_response(prompt)
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})

# --- 5. ì•± ì‹¤í–‰ ---
if __name__ == "__main__":
    if "logged_in" not in st.session_state:
        login()
    else:
        main_page()